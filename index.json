
    
    
    
    
    
    
    
    
    [{"authors":null,"categories":null,"content":"Yixin Yang is a Ph.D. Student at the Camera Intelligence Lab, National Engineering Research Center of Visual Technology, School of Computer Science, Peking University.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"","publishdate":"0001-01-01T00:00:00Z","relpermalink":"","section":"authors","summary":"Yixin Yang is a Ph.D. Student at the Camera Intelligence Lab, National Engineering Research Center of Visual Technology, School of Computer Science, Peking University.\n","tags":null,"title":"Yixin Yang 杨溢鑫","type":"authors"},{"authors":["Yixin Yang","Jinxiu Liang","Bohan Yu","Yan Chen","Jimmy S. Ren","Boxin Shi"],"categories":null,"content":"","date":1704067200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1704067200,"objectID":"016f632e136475a5b806310c7306e014","permalink":"https://yixinyang-00.github.io/publication/ev-latency/","publishdate":"2024-05-19T06:50:04.915138Z","relpermalink":"/publication/ev-latency/","section":"publication","summary":"","tags":null,"title":"Learning Latency Correction for Event-guided Deblurring and Frame Interpolation","type":"publication"},{"authors":["Yixin Yang, Jin Han, Jinxiu Liang, Imari Sato, Boxin Shi"],"categories":null,"content":"","date":1696118400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1696118400,"objectID":"99a90c48d3eeaa09998586e7b80a6ad3","permalink":"https://yixinyang-00.github.io/publication/yang-2023-hd-rev/","publishdate":"2023-11-30T12:15:35.848136Z","relpermalink":"/publication/yang-2023-hd-rev/","section":"publication","summary":"","tags":null,"title":"Learning Event Guided High Dynamic Range Video Reconstruction","type":"publication"},{"authors":["Jinxiu Liang","Yixin Yang","Boyu Li","Peiqi Duan","Yong Xu","Boxin Shi"],"categories":null,"content":"","date":1688169600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1688169600,"objectID":"766705c1b74e1b5d03c61180b64fbb0f","permalink":"https://yixinyang-00.github.io/publication/liang-2023-evlowlight/","publishdate":"2023-11-30T12:15:35.837734Z","relpermalink":"/publication/liang-2023-evlowlight/","section":"publication","summary":"","tags":null,"title":"Coherent Event Guided Low-Light Video Enhancement","type":"publication"},{"authors":["Hanyue Lou","Minggui Teng","Yixin Yang","Boxin Shi"],"categories":null,"content":"","date":1685577600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1685577600,"objectID":"17356f9279c1abcb693c86c86644c251","permalink":"https://yixinyang-00.github.io/publication/lou-2023-cvpr/","publishdate":"2023-11-30T12:15:35.855923Z","relpermalink":"/publication/lou-2023-cvpr/","section":"publication","summary":"","tags":null,"title":"All-in-Focus Imaging From Event Focal Stack","type":"publication"},{"authors":["Yixin Yang","Jin Han","Jinxiu Liang","Imari Sato","Boxin Shi"],"categories":null,"content":" Yixin Yang1,2 Jin Han3,4 Jinxiu Liang1,2 Imari Sato3,4 Boxin Shi*,1,2\n1 National Key Laboratory for Multimedia Information Processing, School of Computer Science, Peking University\n2 National Engineering Research Center of Visual Technology, School of Computer Science, Peking University\n3 Graduate School of Information Science and Technology, The University of Tokyo 4 National Institute of Informatics\n{yangyixin93, cssherryliang, shiboxin}@pku.edu.cn  {jinhan, imarik}@nii.ac.jp\nAbstract Limited by the trade-off between frame rate and exposure time when capturing moving scenes with conventional cameras, frame based HDR video reconstruction suffers from scene-dependent exposure ratio balancing and ghosting artifacts. Event cameras provide an alternative visual representation with a much higher dynamic range and temporal resolution free from the above issues, which could be an effective guidance for HDR imaging from LDR videos. In this paper, we propose a multimodal learning framework for event guided HDR video reconstruction. In order to better leverage the knowledge of the same scene from the two modalities of visual signals, a multimodal representation alignment strategy to learn a shared latent space and a fusion module tailored to complementing two types of signals for different dynamic ranges in different regions are proposed. Temporal correlations are utilized recurrently to suppress the flickering effects in the reconstructed HDR video. The proposed HDRev-Net demonstrates state-of-the-art performance quantitatively and qualitatively for both synthetic and real-world data.\nAnimated Results Your browser does not support the video. Supplementary Video Your browser does not support the video. BibTex @inproceedings{yang2023HDRev, author = {Yixin Yang, Jin Han, Jinxiu Liang, Imari Sato, Boxin Shi}, booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, title = {Learning Event Guided High Dynamic Range Video Reconstruction}, year = {2023} } ","date":1678492800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1678492800,"objectID":"efc13a4a60a9ef7c480cf9b37d6c61b5","permalink":"https://yixinyang-00.github.io/project/hdrev/","publishdate":"2023-03-11T00:00:00Z","relpermalink":"/project/hdrev/","section":"project","summary":"We propose a multimodal learning framework for event guided HDR video reconstruction, which including multimodal representation alignment, confidence guided multimodal fusion and temporal context encoding. The proposed HDRev-Net demonstrates state-of-the-art performance quantitatively and qualitatively for both synthetic and real-world data.","tags":["Event Cameara","HDR"],"title":"Learning Event Guided High Dynamic Range Video Reconstruction","type":"publications"},{"authors":["Jin Han","Yixin Yang","Peiqi Duan","Chu Zhou","Lei Ma","Chao Xu","Tiejun Huang","Imari Sato","Boxin Shi"],"categories":null,"content":"","date":1672531200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1672531200,"objectID":"33ec119cf3cabec04fc8e73dc8f7afc0","permalink":"https://yixinyang-00.github.io/publication/han-2022-neurimg-hdr/","publishdate":"2023-12-01T02:21:33.880995Z","relpermalink":"/publication/han-2022-neurimg-hdr/","section":"publication","summary":"","tags":null,"title":"Hybrid High Dynamic Range Imaging fusing Neuromorphic and Conventional Images","type":"publication"},{"authors":["Jin Han","Yixin Yang","Chu Zhou","Chao Xu","Boxin Shi"],"categories":null,"content":"","date":1609459200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1609459200,"objectID":"7b11cda067b86c4ce155a5f1ff26415b","permalink":"https://yixinyang-00.github.io/publication/ev-int-sr/","publishdate":"2023-12-01T02:21:33.891838Z","relpermalink":"/publication/ev-int-sr/","section":"publication","summary":"","tags":null,"title":"EvIntSR-Net: Event Guided Multiple Latent Frames Reconstruction and Super-resolution","type":"publication"},{"authors":[],"categories":[],"content":"Create slides in Markdown with Wowchemy Wowchemy | Documentation\nFeatures Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides Controls Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click PDF Export Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026#34;blueberry\u0026#34; if porridge == \u0026#34;blueberry\u0026#34;: print(\u0026#34;Eating...\u0026#34;) Math In-line math: $x + y = z$\nBlock math:\n$$ f\\left( x \\right) = ;\\frac{{2\\left( {x + 4} \\right)\\left( {x - 4} \\right)}}{{\\left( {x + 4} \\right)\\left( {x + 1} \\right)}} $$\nFragments Make content appear incrementally\n{{% fragment %}} One {{% /fragment %}} {{% fragment %}} **Two** {{% /fragment %}} {{% fragment %}} Three {{% /fragment %}} Press Space to play!\nOne Two Three A fragment can accept two optional parameters:\nclass: use a custom style (requires definition in custom CSS) weight: sets the order in which a fragment appears Speaker Notes Add speaker notes to your presentation\n{{% speaker_note %}} - Only the speaker can read these notes - Press `S` key to view {{% /speaker_note %}} Press the S key to view the speaker notes!\nOnly the speaker can read these notes Press S key to view Themes black: Black background, white text, blue links (default) white: White background, black text, blue links league: Gray background, white text, blue links beige: Beige background, dark text, brown links sky: Blue background, thin dark text, blue links night: Black background, thick white text, orange links serif: Cappuccino background, gray text, brown links simple: White background, black text, blue links solarized: Cream-colored background, dark green text, blue links Custom Slide Customize the slide style and background\n{{\u0026lt; slide background-image=\u0026#34;/media/boards.jpg\u0026#34; \u0026gt;}} {{\u0026lt; slide background-color=\u0026#34;#0000FF\u0026#34; \u0026gt;}} {{\u0026lt; slide class=\u0026#34;my-style\u0026#34; \u0026gt;}} Custom CSS Example Let’s make headers navy colored.\nCreate assets/css/reveal_custom.css with:\n.reveal section h1, .reveal section h2, .reveal section h3 { color: navy; } Questions? Ask\nDocumentation\n","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1549324800,"objectID":"0e6de1a61aa83269ff13324f3167c1a9","permalink":"https://yixinyang-00.github.io/slides/example/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/slides/example/","section":"slides","summary":"An introduction to using Wowchemy's Slides feature.","tags":[],"title":"Slides","type":"slides"}]